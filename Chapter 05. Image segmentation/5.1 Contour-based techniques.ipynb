{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Contour-based techniques for image segmentation\n",
    "\n",
    "Image segmentation is the process of **assigning a label to every pixel in an image** such that pixels with the same label share certain characteristics. As a consequence, it produces regions whose pixels have similar properties (*e.g.* intensity, color, texture, or location in the image) which have a geometric and semantic meaning (see Fig.1). The result of image segmentation could be:\n",
    "- a set of segments that collectively cover the entire image (e.g. thresholding), \n",
    "- or a set of contours extracted from the image (e.g. edge detection).\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"./images/image-segmentation-example.png\" width=\"550\">\n",
    "  <figcaption>Fig. 1: Example of image segmentation where each region corresponds to an object in the scene.</figcaption>\n",
    "</figure>\n",
    "\n",
    "Conceptually, two traditional approaches to image segmentation exist (see Fig. 2):\n",
    "- **Top-down segmentation**, which considers that pixels from the same object in the scene should be in the same segmented region.\n",
    "- **Bottom-up segmentation**, which establishes that similar pixels in the image must be in the same segmented region. $\\\\[5pt]$\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img img src=\"./images/bottom-up_top-down-segmentation.png\" width=\"500\">\n",
    "  <figcaption>Fig. 2. An example of top-down and bottom-up approaches. Adopted from <a href=\"myfootnote1\">[1]</a></figcaption>\n",
    "</figure>\n",
    "\n",
    "We put the spotlight here on bottom-up segmentation approaches. Methods following such approach can be grouped into:\n",
    "- **Contour-based techniques**, which attemp to identify the image regions by detecting their contours.\n",
    "- **Region-based techniques** that group together pixels that are similar. \n",
    "\n",
    "\n",
    "In this book we are going to experience both, starting with **contour-based techniques**, whose are based on detecting specific contours in the image (e.g. circles). In this context, image contours are defined as edge pixels that enclose a region.  \n",
    "\n",
    "Contour-based techniques could be roughly classified into:\n",
    "- **Local tecniques.** Try to segment regions by detecting closed contours, which typically enclose pixels with similar intensities.\n",
    "   - LoG + zero crossing.\n",
    "   - Edge following (Canny operator).\n",
    "- **Global techniques.** Detect particular shapes in the image (circles, lines, etc.).\n",
    "   - Hough transform. \n",
    "   \n",
    "This notebook will cover the **Hough transform** (<a href=\"#511\">section 5.1.1</a>), a contour-based technique that can be used for detecting regions with an arbitrary shape in images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem context - Self-driving car \n",
    "\n",
    "A prestigious company located at PTA (The Andalusia Technology Park) is organizing a [hackathon](https://en.wikipedia.org/wiki/Hackathon) for this year in order to motivate college students to make further progress in the autonomous cars field. Computer vision students at UMA decided to take part in it, but the organizers have posed an initial basic task to guarantee that participants have expertise in image processing techniques. \n",
    "\n",
    "This way, the company sent to students a task for **implementing a basic detector of road lane lines using OpenCV in python**. We are lucky! These are two tools that we know well ;).\n",
    "\n",
    "Detecting lines in a lane is a fundamental task for autonomous vehicles while driving on the road. It is the building block to other path planning and control actions like breaking and steering. \n",
    "\n",
    "So here we are! We are going to detect road lane lines using Hough transform in OpenCV.$\\\\[5pt]$ \n",
    "\n",
    "<img src=\"./images/car.gif\" width=\"400\" align=\"center\">$\\\\[10pt]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy.stats as stats\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "images_path = './images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.1 Hough transform <a id=\"511\"></a>\n",
    "\n",
    "The **Hough Transform** is a technique for the detection of arbitrary shapes in an image. For that, such shapes must be expressed in:\n",
    "\n",
    "- analytical form (**classic Hough**), e.g. using the mathematical representation of lines, circles, ellipses, etc., or \n",
    "- in a numerical form (**generalized Hough**) where the shape is given by a table. \n",
    "\n",
    "Since our goal is to detect lines, we will focus here on analytically expressed shapes. Specifically, a line can be represented analytically as:\n",
    "\n",
    "$$y = mx + n$$\n",
    "\n",
    "or in its parametric form, as:\n",
    "\n",
    "$$\\rho = x \\cos \\theta + y \\sin \\theta$$\n",
    "\n",
    "where $\\rho$ is the perpendicular distance from the origin $(0,0)$ to the line, and $\\theta$ is the angle formed by this perpendicular line and the horizontal axis measured in counter-clockwise (see Fig. 3). Thereby, we are going to represent lines using the pair of parameters $(\\rho, \\theta)$.\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"./images/houghlines.svg\" width=\"250\">\n",
    "  <figcaption>Fig. 3. Parametric representation of a line.</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "The Hough transform works by a voting procedure, which is carried out in a parameter space ($\\rho,\\theta$ in our case). This technique consists of the following steps:\n",
    "\n",
    "1. **Build an accumulator matrix**, where rows index the possible values of $\\rho$, and columns those for $\\theta$. For example, if the possible values for $\\rho$ are $0, 1, 2, \\ldots d$ (where $d$ is the max distance e.g. diagonal size of the image) and those for $\\theta$ are $0, 1, 2 \\ldots 179$, the matrix shape would be $(d,180)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define possible rho and theta values\n",
    "theta_values = [0,np.pi/4,np.pi/2,3*np.pi/4]\n",
    "rho_values = [0,1,2,3,4,5]\n",
    "\n",
    "# Create the accumulator\n",
    "acc = np.zeros([len(rho_values),len(theta_values)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Binarize the input image** to obtain pixels that are candidates to belong to the shape contours (e.g. by applying an edge detector)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates of white points in binary image\n",
    "xs = np.array([1,2,3])\n",
    "ys = np.array([2,3,4])\n",
    "\n",
    "# Show them!\n",
    "plt.subplot(221)\n",
    "plt.plot(xs,ys,'rx')\n",
    "axes = plt.gca()\n",
    "axes.set_xlim([0,4])\n",
    "axes.set_ylim([0,6])\n",
    "plt.title('White pixels in binary image');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. For each candidate (white pixel):\n",
    "   1. **Evaluate**: Since the point coordinates $(x,y)$ are known, place them in the line parametric form and iterate over the possible values of $\\theta$ to obtain the values for $\\rho$. In the previous example $\\rho_i = x \\cos \\theta_i + y \\sin \\theta_i, \\forall i\\in[0,180]$\n",
    "   2. **Vote**: For every obtained pair $(\\rho_i, \\theta_i)$ increment by one the value of its associated cell in the accumulator.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each white pixel\n",
    "for i in range (0,len(xs)):\n",
    "    x = xs[i]\n",
    "    y = ys[i]\n",
    "    \n",
    "    # Show the point voting\n",
    "    subplot_index = str(32) + str(i*2+1)\n",
    "    plt.subplot(int(subplot_index))        \n",
    "    plt.plot(xs,ys,'rx')\n",
    "    plt.plot(x,y,'co')\n",
    "    plt.title('Pixel being evaluated at iteration ' + str(i+1))\n",
    "    \n",
    "    # Ecaluate the (x,y) coordinates for different values of theta, and \n",
    "    # retrieve rho\n",
    "    for theta_index in range(0,len(theta_values)):\n",
    "        theta = theta_values[theta_index]\n",
    "        rho = x*np.cos(theta) + y*np.sin(theta)\n",
    "        rho = int(np.round(rho))\n",
    "        # Vote!\n",
    "        acc[rho][theta_index] += 1.0\n",
    "        \n",
    "    # Show the acccumulator\n",
    "    subplot_index = str(32) + str(i*2+2)\n",
    "    plt.subplot(int(subplot_index))        \n",
    "    plt.imshow(acc,cmap='gray',vmax=3);\n",
    "    plt.title('Accumulator values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Finally, **obtain the shape candidates** by setting a threshold to control how many votes needs a pair $(\\rho, \\theta)$  to be considered a line, and by applying local maxima in the accumulator space. $\\\\[10pt]$\n",
    "  \n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"./images/houghlinesdemo.gif\" width=\"400\" align=\"center\">\n",
    "  <figcaption>Fig. 3. Left, image space. Right, parameter space illustrating the evolution of the votes. Note that in this example $\\theta$ have only 8 possible values.</figcaption>\n",
    "</figure>\n",
    "\n",
    "\n",
    "The idea behind this algorithm is that when a pixel in the image space votes for all the lines that go through it in the parameter space, when a second pixel belonging to the same line votes, then the line connecting both pixels would have two votes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"orange\">OpenCV pill</font>\n",
    "    \n",
    "OpenCV implements the method [`cv2.HoughLines()`](https://docs.opencv.org/4.2.0/dd/d1a/group__imgproc__feature.html#ga46b4e588934f6c8dfd509cc6e0e4545a) for detecting lines using the Hough transform. However, prior to its usage, and as commented in the `step 1.` of the algorithm, it is needed a binary image. For that we are going to resort to our old friend the Canny algorithm, so the detected edges will be the white pixes in the binary image.\n",
    "\n",
    "As we now, noisy images seriously hamper the performance of computer vision techniques, and since [cv2.Canny()](https://docs.opencv.org/4.2.0/dd/d1a/group__imgproc__feature.html#ga04723e007ed888ddf11d9ba04e2232de) does not include blurring, we provide here a method called `gaussian_smoothing()` to assist you in that task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_smoothing(image, sigma, w_kernel):\n",
    "    \"\"\" Blur and normalize input image.   \n",
    "    \n",
    "        Args:\n",
    "            image: Input image to be binarized\n",
    "            sigma: Standard deviation of the Gaussian distribution\n",
    "            w_kernel: Kernel aperture size\n",
    "                    \n",
    "        Returns: \n",
    "            binarized: Blurred image\n",
    "    \"\"\"   \n",
    "    \n",
    "    # Define 1D kernel\n",
    "    s=sigma\n",
    "    w=w_kernel\n",
    "    kernel_1D = [np.exp(-z*z/(2*s*s))/np.sqrt(2*np.pi*s*s) for z in range(-w,w+1)]\n",
    "    \n",
    "    # Apply distributive property of convolution\n",
    "    kernel_2D = np.outer(kernel_1D,kernel_1D)\n",
    "    \n",
    "    # Blur image\n",
    "    smoothed_img = cv2.filter2D(image,cv2.CV_8U,kernel_2D)\n",
    "    \n",
    "    # Normalize to [0 254] values\n",
    "    smoothed_norm = np.array(image.shape)\n",
    "    smoothed_norm = cv2.normalize(smoothed_img,None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    return smoothed_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1: Detecting lines with Hough</i></b></span>**\n",
    "\n",
    "**Your first task is** to apply [`cv2.HoughLines()`](https://docs.opencv.org/4.2.0/dd/d1a/group__imgproc__feature.html#ga46b4e588934f6c8dfd509cc6e0e4545a) to the image `car.png`, a test image taken from the frontal camera of a car. Draw the resultant lines using [`cv2.line()`](https://docs.opencv.org/4.2.0/d6/d6e/group__imgproc__draw.html#ga7078a9fae8c7e7d13d24dac2520ae4a2).\n",
    "\n",
    "The main inputs of `cv2.HoughLines()` are:\n",
    "\n",
    "- *image*: binary input image\n",
    "- *rho*: distance resolution of the accumulator in pixels (usually 1, it may be bigger for high resolution images) \n",
    "- *theta*: angle resolution of the accumulator in radians. (usually $\\frac{\\pi}{180}$)$\\\\[2pt]$\n",
    "- *threshold*: only line candidates having a number of votes $>$ threshold are returned.\n",
    "\n",
    "And it returns:\n",
    "- a  $( n\\_lines x 1 x 2 )$ array containing, in each row, the parameters of each detected line in the $[\\rho,\\theta]$ format.\n",
    "\n",
    "*Note that, for drawing the lines, you have to [transform the resultant lines](https://answers.opencv.org/question/21132/draw-the-lines-detected-by-cvhoughlines/) from the $(\\rho, \\theta)$ space to Cartesian coordinates.*\n",
    "\n",
    "Try different parameter values until you get something like this:\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"./images/hough-lines-result.png\" align=\"center\">\n",
    "  <figcaption>Fig. 4. Example of lines detection.</figcaption>\n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 1\n",
    "# Read the image\n",
    "image = cv2.imread(images_path + \"car.png\",-1)\n",
    "\n",
    "# Convert to RGB and get gray image\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Blur the gray image\n",
    "gray = gaussian_smoothing(gray,2,5)\n",
    "\n",
    "# Apply Canny algorithm\n",
    "edges = cv2.Canny(gray,100,200,apertureSize = 3)\n",
    "\n",
    "# Search for lines using Hough transform\n",
    "lines = cv2.HoughLines(edges, rho=1, theta=np.pi/180, threshold=165) \n",
    "#Subiendo el umbral a 165 desaparece la linea del morro del choche\n",
    "\n",
    "# For each line\n",
    "for i in range(0, len(lines)):\n",
    "    \n",
    "    # Transform from polar coordinates to cartesian coordinates\n",
    "    rho = lines[i][0][0]\n",
    "    theta = lines[i][0][1]\n",
    "    \n",
    "    a = math.cos(theta)\n",
    "    b = math.sin(theta)\n",
    "    \n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    \n",
    "    # Get two points in that line \n",
    "    x1 = int(x0 + 2000*(-b));\n",
    "    y1 = int(y0 + 2000*(a))\n",
    "    pt1 = (x1,y1)\n",
    "    x2 = int(x0 - 2000*(-b))\n",
    "    y2 = int(y0 - 2000*(a))\n",
    "    pt2 = (x2,y2)\n",
    "    \n",
    "    # Draw the line in the RGB image\n",
    "    cv2.line(image, pt1, pt2, (255,0,0), 3, cv2.LINE_AA)\n",
    "\n",
    "# Show resultant image\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2.1 Probabilistic Hough transform\n",
    "\n",
    "For high-resolution images and large accumulator sizes the Hough transform may need long execution times. However, in applications like autonomous cars a fast execution is mandatory. For example, having a car moving at 100km/h covers $\\sim28$ meters in a second. Imagine how much lines can change in that time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color=\"orange\">OpenCV pill</font>\n",
    "    \n",
    "OpenCV provides with the method [`cv2.HoughLinesP()`](https://docs.opencv.org/4.2.0/dd/d1a/group__imgproc__feature.html#ga8618180a5948286384e3b7ca02f6feeb) a more complex implementation of the Hough Line Transform, which is called **probabilistic Hough Transform**. This alternative does not take all the points in the binary image into account, but a random subset of them that are still enough for line detection. This also results in lower thresholds when deciding if a line exists or not.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 2: Another option for detecting lines</i></b></span>**\n",
    "\n",
    "Apply [`cv2.HoughLinesP()`](https://docs.opencv.org/4.2.0/dd/d1a/group__imgproc__feature.html#ga8618180a5948286384e3b7ca02f6feeb) to the image `car.png` and draw the detected lines.\n",
    "\n",
    "This function returns:\n",
    "- line segments `[x1,y1,x2,y2]` instead of the line equation parameters.\n",
    "\n",
    "For that, two additional arguments are needed:\n",
    "- minLineLength: line segments shorter than that are rejected. \n",
    "- maxLineGap: maximum allowed gap between points on the same line to link them.\n",
    "\n",
    "Try different parameter values until you get something like this:\n",
    "\n",
    "<figure style=\"text-align:center\">\n",
    "  <img src=\"./images/probabilistic-hough-lines-result.png\" align=\"center\">\n",
    "  <figcaption>Fig. 5. Lines detection example with the probabilistic Hough Transform.</figcaption>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Assigment 2\n",
    "# Read the image\n",
    "image = cv2.imread(images_path + \"car.png\",-1)\n",
    "\n",
    "# Convert to RGB and get gray image\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "# Blur the gray image\n",
    "gray = gaussian_smoothing(gray,1,2)\n",
    "\n",
    "# Apply Canny algorithm\n",
    "edges = cv2.Canny(gray,100,200,apertureSize = 3)\n",
    "\n",
    "# Search for lines using probabilistic Hough transform\n",
    "rho = 1\n",
    "theta = np.pi/180\n",
    "threshold = 100\n",
    "lines = cv2.HoughLinesP(edges, rho, theta, threshold,\n",
    "                        minLineLength=200,maxLineGap=15)\n",
    "# For each line\n",
    "for line in lines:\n",
    "    \n",
    "    # Draw the line in the RGB image\n",
    "    x1,y1,x2,y2 = line[0]\n",
    "    cv2.line(image,(x1,y1),(x2,y2),(255,0,0),2)\n",
    "\n",
    "# Show resultant image\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (1)</i></b></font>\n",
    "\n",
    "Now that you have played with the Hough Transform, **answer the following questions**:\n",
    "\n",
    "- In the first assignment, we obtained an image with a number of red lines drawn on it. However, these lines goes over pixels in the image that do not contains lines! (*e.g.* belonging to the sky). What could we do to fix this, that is, obtain the pixels belonging to lines in the image?\n",
    "  \n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Esto ocurre debido a que inicialmente trabajamosocn lineas, que son infinitas, no trabajamos con segmentos, que si son finitos. Para trabajar con segmentos en lugar de lineas, una de las posibles soluciones sería tomar solo en consideración los puntos que han votado y han participado en la votación de la cada recta, de manera que quedaría un segmento con cierta precisión en lugar de una recta infinita.</i></p>\n",
    "    \n",
    "- Without restrictions regarding execution time, which method would you use, Hough Transform or its probabilistic counterpart?\n",
    "  \n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Sin ninguna restricción, es mejor usar la transformada de Hought, ya que cada pixel de los bordes detectados va a votar, mientras que en el caso probabilístico solo van a votar algunos para ahorrar tiempo de ejeccución, así que usar la Transformada de Hough va a ser mas fiable y precisa.</i></p> \n",
    "    \n",
    "- Could there be a cell in the accumulator with a value higher than the number of white pixels in the binary image? why?\n",
    "  \n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Esto solo podría pasar en el caso de que un pixel al votar pudiera añadir mas de una votación para la misma combinación de Theta y Rho, lo cual no debería de ser posible. La única forma que se me ocurre que puede llegar a pasar esto es si trabajamos con una precisioón de theta y rho muy superior a la precisión de la imagen con respecto al número de pixeles de esta, es decir, si mi escala para theta y rho son lo números reales, pero luego tengo que discretizar los resultados de las votaciones para pasarlo a pixeles, podría darse una situación como la descrita en el enunciado</i></p> \n",
    "    \n",
    "- Which should be the maximum value for $\\rho$ in the accumulator? Why?\n",
    "  \n",
    "    <p style=\"margin: 4px 0px 0px 5px; color:blue\"><i>Pues teniendo en cuenta la forma parametrica de una recta, es decir, rho=x*cos(theta) + y*sin(theta), el valor máximo de rho va a venir determinado por el número de pixeles que tiene la imagen.</i></p>     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Terrific work! In the road lane lines detection context you have learned:\n",
    "- to detect shapes in images using Hough transform .\n",
    "\n",
    "Also, you obtained some knowledge about: \n",
    "\n",
    "- self-driving cars and computer vision, and\n",
    "- lane line detection for autonomous cars.\n",
    "\n",
    "See you in the next one! Keep learning!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}